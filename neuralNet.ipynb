{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'CUB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Path to run on your own system\n",
    "res101 = scipy.io.loadmat('C:/Users/Zach/Documents/NorthEastern/SmallDataMachineLearning/Code/ESZSL/Data/xlsa17/data/'+dataset+'/res101.mat')\n",
    "att_splits = scipy.io.loadmat('C:/Users/Zach/Documents/NorthEastern/SmallDataMachineLearning/Code/ESZSL/Data/xlsa17/data/'+dataset+'/att_splits.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the correct naming conventions to get the loctions\n",
    "trainval_loc = 'trainval_loc'\n",
    "train_loc = 'train_loc'\n",
    "val_loc = 'val_loc'\n",
    "test_loc = 'test_unseen_loc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RES101 is Resnet 101, this is the output from CNN\n",
    "labels = res101['labels']\n",
    "#Array of training labels (class label)\n",
    "labels_train = labels[np.squeeze(att_splits[train_loc]-1)]\n",
    "#array of validation labels\n",
    "labels_val = labels[np.squeeze(att_splits[val_loc]-1)]\n",
    "#train + validation labels\n",
    "labels_trainval = labels[np.squeeze(att_splits[trainval_loc]-1)]\n",
    "#test labels\n",
    "labels_test = labels[np.squeeze(att_splits[test_loc]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all unique labels, should be 200 for birds\n",
    "unique_labels = np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_seen = np.unique(labels_train)\n",
    "val_labels_unseen = np.unique(labels_val)\n",
    "trainval_labels_seen = np.unique(labels_trainval)\n",
    "test_labels_unseen = np.unique(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_train now should be an index into the train_labels seen\n",
    "#example: anything that had 200 as a label, now is 99 which is the last index in train_labels seen\n",
    "#which aligns with label 200\n",
    "i = 0\n",
    "for labels in train_labels_seen:\n",
    "    labels_train[labels_train == labels] = i    \n",
    "    i = i+1\n",
    "j = 0\n",
    "for labels in val_labels_unseen:\n",
    "    labels_val[labels_val == labels] = j\n",
    "    j = j+1\n",
    "k = 0\n",
    "for labels in trainval_labels_seen:\n",
    "    labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "l = 0\n",
    "for labels in test_labels_unseen:\n",
    "    labels_test[labels_test == labels] = l\n",
    "    l = l+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all features of all data\n",
    "X_features = res101['features']\n",
    "#select those for the training\n",
    "train_vec = X_features[:,np.squeeze(att_splits[train_loc]-1)]\n",
    "#validation set\n",
    "val_vec = X_features[:,np.squeeze(att_splits[val_loc]-1)]\n",
    "#train+validation\n",
    "trainval_vec = X_features[:,np.squeeze(att_splits[trainval_loc]-1)]\n",
    "#last the test features\n",
    "test_vec = X_features[:,np.squeeze(att_splits[test_loc]-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attribute Signature matrix (all)\n",
    "#All normalized to have unit 12 norm\n",
    "signature = att_splits['att']\n",
    "#getting the training,validation,train+val,and the test signatures\n",
    "train_sig = signature[:,(train_labels_seen)-1]\n",
    "val_sig = signature[:,(val_labels_unseen)-1]\n",
    "trainval_sig = signature[:,(trainval_labels_seen)-1]\n",
    "test_sig = signature[:,(test_labels_unseen)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params for train and val set\n",
    "m_train = labels_train.shape[0]\n",
    "n_val = labels_val.shape[0]\n",
    "z_train = len(train_labels_seen)\n",
    "z1_val = len(val_labels_unseen)\n",
    "\n",
    "#params for trainval and test set\n",
    "m_trainval = labels_trainval.shape[0]\n",
    "n_test = labels_test.shape[0]\n",
    "z_trainval = len(trainval_labels_seen)\n",
    "z1_test = len(test_labels_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting ground truths for the the classes\n",
    "#ground truth for train \n",
    "gt_train = 0*np.ones((m_train, z_train))\n",
    "gt_train[np.arange(m_train), np.squeeze(labels_train)] = 1\n",
    "\n",
    "#grountruth for trainval \n",
    "gt_trainval = 0*np.ones((m_trainval, z_trainval))\n",
    "gt_trainval[np.arange(m_trainval), np.squeeze(labels_trainval)] = 1\n",
    "\n",
    "#train set dimensions\n",
    "d_train = train_vec.shape[0] #num of dimensions of features\n",
    "a_train = train_sig.shape[0] #num of attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0106, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0438],\n",
       "        [0.0106, 0.0113, 0.0351,  ..., 0.0033, 0.1118, 0.0281],\n",
       "        [0.0071, 0.0094, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0092, 0.0027, 0.0028,  ..., 0.0056, 0.0821, 0.0602],\n",
       "        [0.0253, 0.0213, 0.0151,  ..., 0.0000, 0.0584, 0.0770],\n",
       "        [0.0207, 0.0586, 0.1582,  ..., 0.1503, 0.0182, 0.0619]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "I am trying to create a Neural Network that will take the features from the images\n",
    "and predict the attributes.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "\n",
    "#going to reassign\n",
    "X = torch.tensor(train_vec)\n",
    "S = torch.tensor(train_sig)\n",
    "Y = torch.tensor(gt_train)\n",
    "\n",
    "# number of features from image\n",
    "inputDim  = X.shape[0]\n",
    "#Number of classes\n",
    "outputDim = S.shape[0]\n",
    "\n",
    "S.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
